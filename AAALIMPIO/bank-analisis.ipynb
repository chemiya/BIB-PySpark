{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bank Marketing Dataset \n",
    "Contiene datos de una campaña de marketing directo de una institución bancaria portuguesa. El objetivo principal de esta campaña era convencer a los clientes de que suscribieran un depósito a plazo fijo. La tarea es predecir si un cliente se suscribirá a un depósito a plazo fijo. Los atributos son:\n",
    "\n",
    "<ul>\n",
    "<li>age: Edad del cliente (numérico).</li>\n",
    "<li>job: Tipo de trabajo (categórico).</li>\n",
    "<li>marital: Estado civil (categórico).</li>\n",
    "<li>education: Nivel de educación (categórico).</li>\n",
    "<li>default: ¿Tiene crédito en default?.</li>\n",
    "<li>balance: Balance promedio anual en la cuenta bancaria (numérico, en euros).</li>\n",
    "<li>housing: ¿Tiene crédito de vivienda?.</li>\n",
    "<li>loan: ¿Tiene préstamo personal?.</li>\n",
    "<li>contact: Tipo de comunicación de contacto (categórico).</li>\n",
    "<li>day: Día del mes en que se realizó el último contacto del cliente (numérico).</li>\n",
    "<li>month: Mes en que se realizó el último contacto del cliente.</li>\n",
    "<li>duration: Duración del último contacto en segundos (numérico).</li>\n",
    "<li>campaign: Número de contactos realizados durante esta campaña para este cliente (numérico).</li>\n",
    "<li>pdays: Número de días que pasaron después de que el cliente fue contactado por última vez desde una campaña anterior (numérico).</li>\n",
    "<li>previous: Número de contactos realizados antes de esta campaña para este cliente (numérico).</li>\n",
    "<li>poutcome: Resultado de la campaña de marketing anterior.</li>\n",
    "<li>y: Variable objetivo (target) que indica si el cliente ha suscrito un depósito a plazo fijo (binario: \"yes\", \"no\").</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SparkContext: Se utiliza para crear RDDs (Resilient Distributed Datasets), que son la estructura de datos fundamental en Spark. SparkContext también administra la comunicación con el cluster Spark, coordinando la ejecución de operaciones en el cluster y administrando la memoria. \\nSparkSession: Es una interfaz unificada de nivel superior que reemplaza a las antiguas clases SQLContext y HiveContext en versiones anteriores de Spark. SparkSession proporciona una forma conveniente de trabajar con Apache Spark y los datos estructurados, como DataFrames y Datasets, así como con SQL. Además de encapsular SparkContext, SparkSession proporciona funcionalidades adicionales\\nEn resumen, SparkContext es la interfaz principal para interactuar con Spark en un nivel más bajo, mientras que SparkSession es una capa más alta que proporciona una interfaz más fácil de usar para trabajar con datos estructurados y realizar operaciones SQL\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''SparkContext: Se utiliza para crear RDDs (Resilient Distributed Datasets), que son la estructura de datos fundamental en Spark. SparkContext también administra la comunicación con el cluster Spark, coordinando la ejecución de operaciones en el cluster y administrando la memoria. \n",
    "SparkSession: Es una interfaz unificada de nivel superior que reemplaza a las antiguas clases SQLContext y HiveContext en versiones anteriores de Spark. SparkSession proporciona una forma conveniente de trabajar con Apache Spark y los datos estructurados, como DataFrames y Datasets, así como con SQL. Además de encapsular SparkContext, SparkSession proporciona funcionalidades adicionales\n",
    "En resumen, SparkContext es la interfaz principal para interactuar con Spark en un nivel más bajo, mientras que SparkSession es una capa más alta que proporciona una interfaz más fácil de usar para trabajar con datos estructurados y realizar operaciones SQL\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Bank Analysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leer conjunto de datos\n",
    "df_pyspark=spark.read.option('header','true').csv('test1.csv',inferSchema=True)\n",
    "#ver esquema\n",
    "df_pyspark.printSchema()\n",
    "#mostrar datos\n",
    "df_pyspark.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con separador ;\n",
    "data = spark.read.csv('cars.csv', header=True, sep=\";\")\n",
    "data.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar tipos\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "# definir esquema\n",
    "schema = StructType([\n",
    "    StructField(name=\"id\", dataType=IntegerType(), nullable=True),\n",
    "    StructField(name=\"name\", dataType=StringType(), nullable=True),\n",
    "    StructField(name=\"category\", dataType=StringType(), nullable=True),\n",
    "    StructField(name=\"quantity\", dataType=IntegerType(), nullable=True),\n",
    "    StructField(name=\"price\", dataType=DoubleType(), nullable=True)\n",
    "])\n",
    "\n",
    "# leer csv\n",
    "csv_file_path = \"./data/products.csv\"\n",
    "df = spark.read.csv(csv_file_path, header=True, schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer datos\n",
    "bank_df = spark.read.csv(\"bank.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.head(3)\n",
    "df_pyspark.tail(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esquema del DataFrame:\n",
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Esquema del DataFrame:\")\n",
    "bank_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del DataFrame:\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| NULL|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| NULL|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| NULL|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| NULL|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|NULL|    0|    0|          244373|   13.0| NULL|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| NULL|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|NULL|    0|    0|            2649|  7.225| NULL|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Primeras filas del DataFrame:\")\n",
    "bank_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis algunas variables:\n",
      "+-------+------------------+------+-------------------+------------------+-----------------+\n",
      "|summary|               Age|   Sex|           Survived|            Pclass|             Fare|\n",
      "+-------+------------------+------+-------------------+------------------+-----------------+\n",
      "|  count|               714|   891|                891|               891|              891|\n",
      "|   mean| 29.69911764705882|  NULL| 0.3838383838383838| 2.308641975308642| 32.2042079685746|\n",
      "| stddev|14.526497332334035|  NULL|0.48659245426485753|0.8360712409770491|49.69342859718089|\n",
      "|    min|              0.42|female|                  0|                 1|              0.0|\n",
      "|    max|              80.0|  male|                  1|                 3|         512.3292|\n",
      "+-------+------------------+------+-------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Análisis algunas variables:\")\n",
    "bank_df.select(\"age\", \"balance\", \"duration\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionar columnas, sin show para guardarlo en otro dataframe\n",
    "df_pyspark.select(['Name','Experience']).show()\n",
    "\n",
    "#seleccionar columnas\n",
    "finalized_data=output.select(\"Independent Features\",\"Salary\")\n",
    "\n",
    "from os import truncate\n",
    "#seleccionar columna\n",
    "data.select(data.Car).show(truncate=False)\n",
    "\n",
    "#otra forma\n",
    "data.select(data['car']).show(truncate=False)\n",
    "\n",
    "#otra forma\n",
    "from pyspark.sql.functions import col\n",
    "data.select(col('car')).show(truncate=False)\n",
    "\n",
    "#seleccionar multiples columnas\n",
    "data.select(data.Car, data.Cylinders).show(truncate=False)\n",
    "\n",
    "#otra forma\n",
    "data.select(data['car'], data['cylinders']).show(truncate=False)\n",
    "\n",
    "#otra forma\n",
    "from pyspark.sql.functions import col\n",
    "data.select(col('CAR'), col('CYLINDERS')).show(truncate=False)\n",
    "\n",
    "# seleccionar columnas\n",
    "selected_columns = df.select(\"id\", \"name\", \"price\")\n",
    "print(\"Selected Columns:\")\n",
    "selected_columns.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ver tipos de las columnas\n",
    "df_pyspark.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resumen de los datos\n",
    "df_pyspark.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#añadir columna en base a otra columna\n",
    "df_pyspark=df_pyspark.withColumn('Experience After 2 year',df_pyspark['Experience']+2)\n",
    "\n",
    "# añadir columna calculada\n",
    "df_with_new_column = df.withColumn(\"revenue\", df.quantity * df.price)\n",
    "print(\"DataFrame with New Column:\")\n",
    "df_with_new_column.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminar columna\n",
    "df_pyspark=df_pyspark.drop('Experience After 2 year')\n",
    "\n",
    "# eliminar columnas\n",
    "dropped_columns = df.drop(\"quantity\", \"category\")\n",
    "print(\"Dropped Columns:\")\n",
    "dropped_columns.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renombrar columna\n",
    "df_pyspark.withColumnRenamed('Name','New Name').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#personas con salario inferior a 20.000, sin show para guardarlo en otro dataframe\n",
    "df_pyspark.filter(\"Salary<=20000\").show()\n",
    "\n",
    "#solo mostrando columnas necesarias\n",
    "df_pyspark.filter(\"Salary<=20000\").select(['Name','age']).show()\n",
    "\n",
    "#otra forma\n",
    "df_pyspark.filter(df_pyspark['Salary']<=20000).show()\n",
    "\n",
    "#or con | y and con &\n",
    "df_pyspark.filter((df_pyspark['Salary']<=20000) & \n",
    "                  (df_pyspark['Salary']>=15000)).show()\n",
    "\n",
    "#opuesto a menores de 20.000\n",
    "df_pyspark.filter(~(df_pyspark['Salary']<=20000)).show()\n",
    "\n",
    "# filtrar segun condicion\n",
    "filtered_data = df.filter(df.quantity > 20)\n",
    "print(\"Filtered Data:\", filtered_data.count())\n",
    "filtered_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir columna tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de pasajeros por clase:\n",
      "+------+-----+\n",
      "|Pclass|count|\n",
      "+------+-----+\n",
      "|     1|  216|\n",
      "|     3|  491|\n",
      "|     2|  184|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de pasajeros por job:\")\n",
    "bank_df.groupBy(\"job\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de supervivencia por género:\n",
      "+------+-------------------+\n",
      "|   Sex|      avg(Survived)|\n",
      "+------+-------------------+\n",
      "|female| 0.7420382165605095|\n",
      "|  male|0.18890814558058924|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupa por housing y calcula media age\n",
    "print(\"Media de age agruando por housing:\")\n",
    "bank_df.groupBy(\"housing\").agg({\"age\": \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edad media de los pasajeros:\n",
      "+-----------------+\n",
      "|         avg(Age)|\n",
      "+-----------------+\n",
      "|29.69911764705882|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Balance medio de los clientes:\")\n",
    "bank_df.agg({\"balance\": \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarifa media pagada por pasajero:\n",
      "+----------------+\n",
      "|       avg(Fare)|\n",
      "+----------------+\n",
      "|32.2042079685746|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Duration media de los clientes:\")\n",
    "bank_df.agg({\"duration\": \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de pasajeros que sobrevivieron:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Número de clientes suscritos:\")\n",
    "bank_df.filter(col(\"y\") == \"yes\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de pasajeros por puerto de embarque:\n",
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|   77|\n",
      "|    NULL|    2|\n",
      "|       C|  168|\n",
      "|       S|  644|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de clientes por education:\")\n",
    "bank_df.groupBy(\"education\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupBy('Horsepower').count().show(5)\n",
    "data.groupBy('Origin','Model').count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cuenta filas\n",
    "num_fils = data.count()\n",
    "print(\"Total de registros:\", num_fils)\n",
    "\n",
    "#columnas\n",
    "num_cols = len(data.columns)\n",
    "\n",
    "#imprimir con formato\n",
    "print(\"El DataFrame tiene {} filas y {} columnas.\".format(num_fils, num_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contar con filtro\n",
    "europa= data.filter(col('Origin')==\"US\").count()\n",
    "print(\"Total de registros en US:\", europa)\n",
    "\n",
    "#contar filtrados\n",
    "usa= data.filter((col('Origin')==\"US\")&(col('Horsepower')==\"175.0\")).count()\n",
    "print(\"Total de registros:\", usa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ascending se puede quitar\n",
    "data.orderBy('Cylinders',ascending=False).show(truncate=False)\n",
    "\n",
    "# ordenamos pr columna\n",
    "sorted_data = df.orderBy(\"price\")\n",
    "print(\"Sorted Data:\")\n",
    "sorted_data.show(10)\n",
    "\n",
    "# orden descendente\n",
    "from pyspark.sql.functions import col, desc\n",
    "sorted_data = df.orderBy(col(\"price\").desc(), col(\"id\").desc())\n",
    "print(\"Sorted Data Descending:\")\n",
    "sorted_data.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionar elementos distintos\n",
    "distinct_rows = df.select(\"category\").distinct()\n",
    "print(\"Distinct Product Categories:\")\n",
    "distinct_rows.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordenar group by resultado\n",
    "data.groupBy('Origin').count().orderBy('count', ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupar y realizar calculo:\n",
    "#agrupo por nombre y sumo salarios\n",
    "df_pyspark.groupBy('Name').sum().show()\n",
    "\n",
    "#agrupo por nombre y calculo media\n",
    "df_pyspark.groupBy('Name').avg().show()\n",
    "\n",
    "#agrupo por departamentos y calculo media\n",
    "df_pyspark.groupBy('Departments').mean().show()\n",
    "\n",
    "#agrupo por departamentos y cuento\n",
    "df_pyspark.groupBy('Departments').count().show()\n",
    "\n",
    "# agrupar y aplicar diferentes funciones sobre cada columna\n",
    "grouped_data = df.groupBy(\"category\").agg({\"quantity\": \"sum\", \"price\": \"avg\"})\n",
    "print(\"Grouped and Aggregated Data:\")\n",
    "grouped_data.show()\n",
    "\n",
    "#agrupa por sexo y calcula media sobreviven\n",
    "print(\"Tasa de supervivencia por género:\")\n",
    "titanic_df.groupBy(\"Sex\").agg({\"Survived\": \"mean\"}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suma de todos los salarios\n",
    "df_pyspark.agg({'Salary':'sum'}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de la clase de los pasajeros por puerto de embarque:\n",
      "+---------------+---+---+---+----+\n",
      "|Pclass_Embarked|  C|  Q|  S|null|\n",
      "+---------------+---+---+---+----+\n",
      "|              3| 66| 72|353|   0|\n",
      "|              1| 85|  2|127|   2|\n",
      "|              2| 17|  3|164|   0|\n",
      "+---------------+---+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Matriz de correlación, con loan y housing\n",
    "print(\"Distribución de loan con housing:\")\n",
    "loan_by_housing = bank_df.crosstab(\"loan\", \"housing\")\n",
    "loan_by_housing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución del puerto de embarque por clase de los pasajeros:\n",
      "+------+--------+-----+\n",
      "|Pclass|Embarked|count|\n",
      "+------+--------+-----+\n",
      "|     1|    NULL|    2|\n",
      "|     1|       C|   85|\n",
      "|     1|       Q|    2|\n",
      "|     1|       S|  127|\n",
      "|     2|       C|   17|\n",
      "|     2|       Q|    3|\n",
      "|     2|       S|  164|\n",
      "|     3|       C|   66|\n",
      "|     3|       Q|   72|\n",
      "|     3|       S|  353|\n",
      "+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Similar pero con group by\n",
    "print(\"Distribución de loan con housing:\")\n",
    "loan_by_housing = bank_df.groupBy(\"loan\", \"housing\").count().orderBy(\"loan\", \"housing\")\n",
    "loan_by_housing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de clientes\n",
    "total_clientes = bank_df.count()\n",
    "total_clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, col\n",
    "# Número de personas con préstamo personal y su porcentaje\n",
    "loan_distribution = bank_df.groupBy(\"loan\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    ((count(\"*\") / total_clientes) * 100).alias(\"percentage\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de hombres y mujeres que embarcaron y su porcentaje sobre el total de pasajeros:\n",
      "+------+-----+-----------------+\n",
      "|   Sex|count|       percentage|\n",
      "+------+-----+-----------------+\n",
      "|female|  314|35.24130190796858|\n",
      "|  male|  577|64.75869809203144|\n",
      "+------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Número de clientes con préstamo personal y su porcentaje sobre el total de clientes:\")\n",
    "loan_distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de pasajeros para cada combinación de puerto de embarque, género y si sobrevivieron:\n",
      "+--------+------+--------+----------+\n",
      "|Embarked|   Sex|Survived|percentage|\n",
      "+--------+------+--------+----------+\n",
      "|    NULL|female|       1|      0.22|\n",
      "|       C|female|       0|      1.01|\n",
      "|       C|female|       1|      7.18|\n",
      "|       C|  male|       0|      7.41|\n",
      "|       C|  male|       1|      3.25|\n",
      "|       Q|female|       0|      1.01|\n",
      "|       Q|female|       1|      3.03|\n",
      "|       Q|  male|       0|      4.26|\n",
      "|       Q|  male|       1|      0.34|\n",
      "|       S|female|       0|      7.07|\n",
      "|       S|female|       1|     15.71|\n",
      "|       S|  male|       0|     40.85|\n",
      "|       S|  male|       1|      8.64|\n",
      "+--------+------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "# Porcentaje combinación atributos\n",
    "y_by_loan_housing_percentage = bank_df.groupBy(\"loan\", \"housing\", \"y\").agg(\n",
    "    (count(\"*\") / total_clientes * 100).alias(\"percentage\")\n",
    ")\n",
    "\n",
    "# Redondear \n",
    "y_by_loan_housing_percentage = y_by_loan_housing_percentage.withColumn(\"percentage\", round(\"percentage\", 2))\n",
    "\n",
    "# Ordenar \n",
    "y_by_loan_housing_percentage = y_by_loan_housing_percentage.orderBy(\"Embarked\", \"Sex\", \"Survived\")\n",
    "\n",
    "# Tabla\n",
    "print(\"Porcentaje de clientes para cada combinación de loan, housing y si se ha suscrito al depósito:\")\n",
    "y_by_loan_housing_percentage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Definir rangos de edades\n",
    "age_ranges = [(i, i + 4) for i in range(0, 100, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|AgeRange|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|   21-25|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|   36-40|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|   26-30|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|   36-40|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|   36-40|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q| Unknown|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|   51-55|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|     1-5|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|   26-30|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|   11-15|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|     1-5|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|   56-60|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| NULL|       S|   21-25|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| NULL|       S|   36-40|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| NULL|       S|   11-15|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| NULL|       S|   56-60|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| NULL|       Q|     1-5|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|NULL|    0|    0|          244373|   13.0| NULL|       S| Unknown|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| NULL|       S|   31-35|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|NULL|    0|    0|            2649|  7.225| NULL|       C| Unknown|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# columna con rango de edad\n",
    "bank_df_with_age_range = bank_df.withColumn(\"AgeRange\", expr(\n",
    "    \"CASE WHEN Age IS NULL THEN 'Unknown' \" +\n",
    "    \"ELSE CAST(FLOOR(Age / 5) * 5 AS INT) + 1 || '-' || CAST(FLOOR(Age / 5) * 5 + 5 AS STRING) END\"\n",
    "))\n",
    "\n",
    "bank_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de frecuencia de pasajeros por rangos de edades de 5 años:\n",
      "+--------+-----+\n",
      "|AgeRange|count|\n",
      "+--------+-----+\n",
      "|     1-5|   40|\n",
      "|   11-15|   16|\n",
      "|   16-20|   86|\n",
      "|   21-25|  114|\n",
      "|   26-30|  106|\n",
      "|   31-35|   95|\n",
      "|   36-40|   72|\n",
      "|   41-45|   48|\n",
      "|   46-50|   41|\n",
      "|   51-55|   32|\n",
      "|   56-60|   16|\n",
      "|    6-10|   22|\n",
      "|   61-65|   15|\n",
      "|   66-70|    4|\n",
      "|   71-75|    6|\n",
      "|   81-85|    1|\n",
      "| Unknown|  177|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# agrupar y ordenar\n",
    "age_distribution = bank_df.groupBy(\"AgeRange\").count().orderBy(\"AgeRange\")\n",
    "\n",
    "# Mostrar \n",
    "print(\"Tabla de frecuencia de clientes por rangos de edades de 5 años:\")\n",
    "age_distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El puerto donde la edad media de los pasajeros que embarcaron fue la más alta es: C\n",
      "La edad media en ese puerto fue: 30.81\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "\n",
    "# Agrupar por job y calcular media edad\n",
    "age_by_job = bank_df.groupBy(\"job\").agg(round(mean(\"Age\"),2).alias(\"AverageAge\")).na.drop()\n",
    "\n",
    "# puerto con edad media mas alta\n",
    "job_with_highest_average_age = age_by_job.orderBy(age_by_job[\"AverageAge\"].desc()).first()\n",
    "\n",
    "# resultado\n",
    "print(\"El trabajo donde la edad media de los clientes es la más alta es:\", job_with_highest_average_age[\"job\"])\n",
    "print(\"La edad media en ese trabajo es:\", job_with_highest_average_age[\"AverageAge\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de pasajeros que sobrevivieron según si tenian hijos:\n",
      "+-----------+------------------+\n",
      "|HadChildren|SurvivalPercentage|\n",
      "+-----------+------------------+\n",
      "|          1|             51.17|\n",
      "|          0|             34.37|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Evaluar si se hicieron contactos previos\n",
    "bank_df_with_previous = bank_df.withColumn(\"HadPrevious\", when(col(\"previous\") > 0, 1).otherwise(0))\n",
    "\n",
    "# porcenajte pasajeros sobrevieiro segun numero de hijos\n",
    "yes_percentage_by_previous = bank_df_with_previous.groupBy(\"HadPrevious\").agg(\n",
    "    (round((count(when(col(\"y\") == \"yes\", True)) / count(\"*\") * 100), 2)).alias(\"YesPercentage\")\n",
    ")\n",
    "\n",
    "# resultado\n",
    "print(\"Porcentaje de clientes que si se suscribieron al depósito con contactos previos:\")\n",
    "yes_percentage_by_previous.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarifa media por clase y puerto de embarque:\n",
      "+------+--------+-----------+\n",
      "|Pclass|Embarked|AverageFare|\n",
      "+------+--------+-----------+\n",
      "|     1|       C|     104.72|\n",
      "|     1|       Q|       90.0|\n",
      "|     1|    NULL|       80.0|\n",
      "|     1|       S|      70.36|\n",
      "|     2|       C|      25.36|\n",
      "|     2|       S|      20.33|\n",
      "|     3|       S|      14.64|\n",
      "|     2|       Q|      12.35|\n",
      "|     3|       C|      11.21|\n",
      "|     3|       Q|      11.18|\n",
      "+------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "# Edad media por loan y clase objetivo\n",
    "average_age_by_loan_and_y = bank_df.groupBy(\"loan\", \"y\") \\\n",
    "    .agg(round(avg(\"age\"), 2).alias(\"AverageAge\"))\n",
    "\n",
    "average_age_by_loan_and_y = average_age_by_loan_and_y.orderBy(average_age_by_loan_and_y[\"AverageAge\"].desc())\n",
    "\n",
    "# resultado\n",
    "print(\"Edad media por loan y si se suscribieron al depósito:\")\n",
    "average_age_by_loan_and_y.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|AgeGroup|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|      20|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|      35|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|      25|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|      35|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|      35|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|    NULL|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|      50|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|       0|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|      25|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|      10|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|       0|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|      55|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| NULL|       S|      20|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| NULL|       S|      35|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| NULL|       S|      10|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| NULL|       S|      55|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| NULL|       Q|       0|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|NULL|    0|    0|          244373|   13.0| NULL|       S|    NULL|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| NULL|       S|      30|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|NULL|    0|    0|            2649|  7.225| NULL|       C|    NULL|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, floor, count, when\n",
    "\n",
    "# intervalos\n",
    "bank_df_with_age_group = bank_df.withColumn(\"AgeGroup\", floor(col(\"age\") / 5) * 5)\n",
    "bank_df_with_age_group.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+\n",
      "|AgeGroup|Pclass|count|\n",
      "+--------+------+-----+\n",
      "|      20|     2|   23|\n",
      "|      60|     2|    2|\n",
      "|      10|     2|    2|\n",
      "|      65|     2|    1|\n",
      "|      60|     3|    2|\n",
      "|      50|     1|   17|\n",
      "|      60|     1|   11|\n",
      "|      35|     3|   24|\n",
      "|      30|     2|   32|\n",
      "|    NULL|     1|   30|\n",
      "|    NULL|     3|  136|\n",
      "|      25|     3|   60|\n",
      "|       5|     3|   17|\n",
      "|      10|     1|    2|\n",
      "|      55|     1|   10|\n",
      "|      35|     2|   16|\n",
      "|      55|     3|    2|\n",
      "|      15|     1|   16|\n",
      "|      15|     3|   54|\n",
      "|      35|     1|   32|\n",
      "+--------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por intervalo de edad y loan y contar. Loan No y agegroup=10 clientes\n",
    "age_class_counts = bank_df_with_age_group.groupBy(\"AgeGroup\", \"loan\").count()\n",
    "age_class_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|AgeGroup|TotalCount|\n",
      "+--------+----------+\n",
      "|      65|         4|\n",
      "|       0|        40|\n",
      "|      50|        32|\n",
      "|      25|       106|\n",
      "|    NULL|       177|\n",
      "|       5|        22|\n",
      "|      10|        16|\n",
      "|      55|        16|\n",
      "|      35|        72|\n",
      "|      80|         1|\n",
      "|      15|        86|\n",
      "|      30|        95|\n",
      "|      20|       114|\n",
      "|      70|         6|\n",
      "|      60|        15|\n",
      "|      40|        48|\n",
      "|      45|        41|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contar el número de clientes en cada grupo de edades. Agegroup 15 de todos los loan =10 clientes\n",
    "total_in_age_group = bank_df_with_age_group.groupBy(\"AgeGroup\").agg(count(\"*\").alias(\"TotalCount\"))\n",
    "total_in_age_group.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+----------+\n",
      "|AgeGroup|Pclass|count|TotalCount|\n",
      "+--------+------+-----+----------+\n",
      "|      20|     2|   23|       114|\n",
      "|      60|     2|    2|        15|\n",
      "|      10|     2|    2|        16|\n",
      "|      65|     2|    1|         4|\n",
      "|      60|     3|    2|        15|\n",
      "|      50|     1|   17|        32|\n",
      "|      60|     1|   11|        15|\n",
      "|      35|     3|   24|        72|\n",
      "|      30|     2|   32|        95|\n",
      "|      25|     3|   60|       106|\n",
      "|       5|     3|   17|        22|\n",
      "|      10|     1|    2|        16|\n",
      "|      55|     1|   10|        16|\n",
      "|      35|     2|   16|        72|\n",
      "|      55|     3|    2|        16|\n",
      "|      15|     1|   16|        86|\n",
      "|      15|     3|   54|        86|\n",
      "|      35|     1|   32|        72|\n",
      "|      45|     3|   12|        41|\n",
      "|      40|     2|   12|        48|\n",
      "+--------+------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unir dataframes distribución edades e intervalos. Edad 15 de todas las loan total 10 clientes\n",
    "age_class_distribution = age_class_counts.join(total_in_age_group, \"AgeGroup\")\n",
    "age_class_distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+----------+----------+\n",
      "|AgeGroup|Pclass|count|TotalCount|Percentage|\n",
      "+--------+------+-----+----------+----------+\n",
      "|      20|     2|   23|       114|     20.18|\n",
      "|      60|     2|    2|        15|     13.33|\n",
      "|      10|     2|    2|        16|      12.5|\n",
      "|      65|     2|    1|         4|      25.0|\n",
      "|      60|     3|    2|        15|     13.33|\n",
      "|      50|     1|   17|        32|     53.13|\n",
      "|      60|     1|   11|        15|     73.33|\n",
      "|      35|     3|   24|        72|     33.33|\n",
      "|      30|     2|   32|        95|     33.68|\n",
      "|      25|     3|   60|       106|      56.6|\n",
      "|       5|     3|   17|        22|     77.27|\n",
      "|      10|     1|    2|        16|      12.5|\n",
      "|      55|     1|   10|        16|      62.5|\n",
      "|      35|     2|   16|        72|     22.22|\n",
      "|      55|     3|    2|        16|      12.5|\n",
      "|      15|     1|   16|        86|      18.6|\n",
      "|      15|     3|   54|        86|     62.79|\n",
      "|      35|     1|   32|        72|     44.44|\n",
      "|      45|     3|   12|        41|     29.27|\n",
      "|      40|     2|   12|        48|      25.0|\n",
      "+--------+------+-----+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcular porcentaje clientes dentro de cada elemento. Edad 15 hay 10 clientes. 3 clase 1, 3 clase 2...\n",
    "age_class_distribution = age_class_distribution.withColumn(\n",
    "    \"Percentage\",\n",
    "    round((col(\"count\") / col(\"TotalCount\")) * 100, 2)\n",
    ")\n",
    "age_class_distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+----------+----------+\n",
      "|AgeGroup|Pclass|count|TotalCount|Percentage|\n",
      "+--------+------+-----+----------+----------+\n",
      "|       0|     1|    3|        40|       7.5|\n",
      "|       0|     2|   12|        40|      30.0|\n",
      "|       0|     3|   25|        40|      62.5|\n",
      "|       5|     2|    5|        22|     22.73|\n",
      "|       5|     3|   17|        22|     77.27|\n",
      "|      10|     1|    2|        16|      12.5|\n",
      "|      10|     2|    2|        16|      12.5|\n",
      "|      10|     3|   12|        16|      75.0|\n",
      "|      15|     1|   16|        86|      18.6|\n",
      "|      15|     2|   16|        86|      18.6|\n",
      "|      15|     3|   54|        86|     62.79|\n",
      "|      20|     1|   18|       114|     15.79|\n",
      "|      20|     2|   23|       114|     20.18|\n",
      "|      20|     3|   73|       114|     64.04|\n",
      "|      25|     1|   16|       106|     15.09|\n",
      "|      25|     2|   30|       106|      28.3|\n",
      "|      25|     3|   60|       106|      56.6|\n",
      "|      30|     1|   18|        95|     18.95|\n",
      "|      30|     2|   32|        95|     33.68|\n",
      "|      30|     3|   45|        95|     47.37|\n",
      "+--------+------+-----+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ordenar\n",
    "age_class_distribution = age_class_distribution.orderBy(\"AgeGroup\", \"loan\")\n",
    "age_class_distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de pasajeros según la edad y la clase por intervalos:\n",
      "+--------+------+-----+----------+----------+\n",
      "|AgeGroup|Pclass|count|TotalCount|Percentage|\n",
      "+--------+------+-----+----------+----------+\n",
      "|       0|     1|    3|        40|       7.5|\n",
      "|       0|     2|   12|        40|      30.0|\n",
      "|       0|     3|   25|        40|      62.5|\n",
      "|       5|     2|    5|        22|     22.73|\n",
      "|       5|     3|   17|        22|     77.27|\n",
      "|      10|     1|    2|        16|      12.5|\n",
      "|      10|     2|    2|        16|      12.5|\n",
      "|      10|     3|   12|        16|      75.0|\n",
      "|      15|     1|   16|        86|      18.6|\n",
      "|      15|     2|   16|        86|      18.6|\n",
      "|      15|     3|   54|        86|     62.79|\n",
      "|      20|     1|   18|       114|     15.79|\n",
      "|      20|     2|   23|       114|     20.18|\n",
      "|      20|     3|   73|       114|     64.04|\n",
      "|      25|     1|   16|       106|     15.09|\n",
      "|      25|     2|   30|       106|      28.3|\n",
      "|      25|     3|   60|       106|      56.6|\n",
      "|      30|     1|   18|        95|     18.95|\n",
      "|      30|     2|   32|        95|     33.68|\n",
      "|      30|     3|   45|        95|     47.37|\n",
      "+--------+------+-----+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Resultado\n",
    "print(\"Distribución de clientes según la edad y si tienen préstamo personal por intervalos:\")\n",
    "age_class_distribution.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------------+-------+-----------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name| Sex| Age|SibSp|Parch|         Ticket|   Fare|      Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------------+-------+-----------+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|male|22.0|    1|    0|      A/5 21171|   7.25|       NULL|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|male|35.0|    0|    0|         373450|   8.05|       NULL|       S|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|male|54.0|    0|    0|          17463|51.8625|        E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|male| 2.0|    3|    1|         349909| 21.075|       NULL|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|male|20.0|    0|    0|      A/5. 2151|   8.05|       NULL|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|male|39.0|    1|    5|         347082| 31.275|       NULL|       S|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|male|NULL|    0|    0|         244373|   13.0|       NULL|       S|\n",
      "|         21|       0|     2|Fynney, Mr. Joseph J|male|35.0|    0|    0|         239865|   26.0|       NULL|       S|\n",
      "|         22|       1|     2|Beesley, Mr. Lawr...|male|34.0|    0|    0|         248698|   13.0|        D56|       S|\n",
      "|         24|       1|     1|Sloper, Mr. Willi...|male|28.0|    0|    0|         113788|   35.5|         A6|       S|\n",
      "|         28|       0|     1|Fortune, Mr. Char...|male|19.0|    3|    2|          19950|  263.0|C23 C25 C27|       S|\n",
      "|         30|       0|     3| Todoroff, Mr. Lalio|male|NULL|    0|    0|         349216| 7.8958|       NULL|       S|\n",
      "|         34|       0|     2|Wheadon, Mr. Edwa...|male|66.0|    0|    0|     C.A. 24579|   10.5|       NULL|       S|\n",
      "|         36|       0|     1|Holverson, Mr. Al...|male|42.0|    1|    0|         113789|   52.0|       NULL|       S|\n",
      "|         38|       0|     3|Cann, Mr. Ernest ...|male|21.0|    0|    0|     A./5. 2152|   8.05|       NULL|       S|\n",
      "|         46|       0|     3|Rogers, Mr. Willi...|male|NULL|    0|    0|S.C./A.4. 23567|   8.05|       NULL|       S|\n",
      "|         51|       0|     3|Panula, Master. J...|male| 7.0|    4|    1|        3101295|39.6875|       NULL|       S|\n",
      "|         52|       0|     3|Nosworthy, Mr. Ri...|male|21.0|    0|    0|     A/4. 39886|    7.8|       NULL|       S|\n",
      "|         56|       1|     1|   Woolner, Mr. Hugh|male|NULL|    0|    0|          19947|   35.5|        C52|       S|\n",
      "|         60|       0|     3|Goodwin, Master. ...|male|11.0|    5|    2|        CA 2144|   46.9|       NULL|       S|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------------+-------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Filtrar se suscribieron al depósito y default no\n",
    "filtered_data = bank_df.filter((col(\"default\") == \"no\") & (col(\"y\") == \"yes\"))\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|Pclass|SurvivedMen|\n",
      "+------+-----------+\n",
      "|     1|         28|\n",
      "|     3|         34|\n",
      "|     2|         15|\n",
      "+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por housing y contar hombre sobrevivieron. Clase 1 sobrevivieron 17.\n",
    "survived_men_by_class = filtered_data.groupBy(\"Pclass\").agg(count(when(col(\"Survived\") == 1, True)).alias(\"SurvivedMen\"))\n",
    "survived_men_by_class.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clase donde mas hombres sobrevivieron en el puerto s\n",
    "most_survived_class = survived_men_by_class.orderBy(survived_men_by_class[\"SurvivedMen\"].desc()).first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clase en la que más hombres sobrevivieron de los que embarcaron en el puerto 'S' fue la clase: 3\n",
      "Número de hombres sobrevivientes en esa clase: 34\n"
     ]
    }
   ],
   "source": [
    "# resultado\n",
    "print(\"La clase en la que más hombres sobrevivieron de los que embarcaron en el puerto 'S' fue la clase:\", most_survived_class[\"Pclass\"])\n",
    "print(\"Número de hombres sobrevivientes en esa clase:\", most_survived_class[\"SurvivedMen\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de filas con al menos un valor nulo es: 0\n"
     ]
    }
   ],
   "source": [
    "# Contar filas con nulos\n",
    "num_rows_with_null = bank_df.na.drop().count()\n",
    "\n",
    "# Resultado\n",
    "print(f\"El número de filas con al menos un valor nulo es: {bank_df.count() - num_rows_with_null}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 'PassengerId' tiene 0 valor(es) nulo(s).\n",
      "Columna 'Survived' tiene 0 valor(es) nulo(s).\n",
      "Columna 'Pclass' tiene 0 valor(es) nulo(s).\n",
      "Columna 'Name' tiene 0 valor(es) nulo(s).\n",
      "Columna 'Sex' tiene 0 valor(es) nulo(s).\n",
      "Columna 'Age' tiene 0 valor(es) nulo(s).\n",
      "Columna 'SibSp' tiene 0 valor(es) nulo(s).\n",
      "Columna 'Parch' tiene 0 valor(es) nulo(s).\n",
      "Columna 'Ticket' tiene 0 valor(es) nulo(s).\n",
      "Columna 'Fare' tiene 0 valor(es) nulo(s).\n",
      "Columna 'Embarked' tiene 0 valor(es) nulo(s).\n"
     ]
    }
   ],
   "source": [
    "# Contar nulos por columnas\n",
    "null_counts = [(column, bank_df.where(col(column).isNull()).count()) for column in bank_df.columns]\n",
    "\n",
    "# Resultados\n",
    "for column, count in null_counts:\n",
    "    print(f\"Columna '{column}' tiene {count} valor(es) nulo(s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|              Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|             22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|             38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|             26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|             35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|             35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|29.69911764705882|    0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|             54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|              2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|             27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|             14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|              4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|             58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|             20.0|    0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|             39.0|    1|    5|          347082| 31.275| NULL|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|             14.0|    0|    0|          350406| 7.8542| NULL|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|             55.0|    0|    0|          248706|   16.0| NULL|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|              2.0|    4|    1|          382652| 29.125| NULL|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|29.69911764705882|    0|    0|          244373|   13.0| NULL|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|             31.0|    1|    0|          345763|   18.0| NULL|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|29.69911764705882|    0|    0|            2649|  7.225| NULL|       C|\n",
      "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Media de age\n",
    "mean_age = bank_df.select(mean(bank_df['Age'])).collect()[0][0]\n",
    "\n",
    "# Nulos reemplazamos por la media\n",
    "bank_df = bank_df.na.fill(mean_age, subset=['Age'])\n",
    "bank_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columna\n",
    "bank_df = bank_df.drop(\"day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "#completa campos vacios con la media de la columna\n",
    "imputer = Imputer(\n",
    "    inputCols=['age', 'Experience', 'Salary'], \n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
    "    ).setStrategy(\"median\")\n",
    "\n",
    "# aplicar transformacion\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elimina nulos y muestra\n",
    "df_pyspark.na.drop().show()\n",
    "\n",
    "#elimina la fila si hay algun nulo\n",
    "#all necesita todos nulos en la fila\n",
    "df_pyspark.na.drop(how=\"any\").show()\n",
    "\n",
    "#si al menos 3 campos completos, mantiene la fila\n",
    "df_pyspark.na.drop(how=\"any\",thresh=3).show()\n",
    "\n",
    "#solo elimina filas si tienen null en esa columna\n",
    "df_pyspark.na.drop(how=\"any\",subset=['Age']).show()\n",
    "\n",
    "#Completar campos vacios de columnas con el valor que queramos\n",
    "df_pyspark.na.fill('Missing Values',['Experience','age']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con month null\n",
    "bank_df = bank_df.na.drop(subset=[\"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de filas con al menos un valor nulo es: 0\n"
     ]
    }
   ],
   "source": [
    "#contar filas con nulos\n",
    "num_rows_with_null = bank_df.na.drop().count()\n",
    "\n",
    "# resultado\n",
    "print(f\"El número de filas con al menos un valor nulo es: {bank_df.count() - num_rows_with_null}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# indices de salida\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=col, outputCol=col + \"Index\")\n",
    "    for col in [\"job\", \"marital\", \"education\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "pipeline = Pipeline(stages=indexers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicarla\n",
    "bank_df_indexed = pipeline.fit(bank_df).transform(bank_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+-----------+--------+-------------+\n",
      "|   Sex|SexIndex|Pclass|PclassIndex|Embarked|EmbarkedIndex|\n",
      "+------+--------+------+-----------+--------+-------------+\n",
      "|  male|     0.0|     3|        0.0|       S|          0.0|\n",
      "|female|     1.0|     1|        1.0|       C|          1.0|\n",
      "|female|     1.0|     3|        0.0|       S|          0.0|\n",
      "|female|     1.0|     1|        1.0|       S|          0.0|\n",
      "|  male|     0.0|     3|        0.0|       S|          0.0|\n",
      "|  male|     0.0|     3|        0.0|       Q|          2.0|\n",
      "|  male|     0.0|     1|        1.0|       S|          0.0|\n",
      "|  male|     0.0|     3|        0.0|       S|          0.0|\n",
      "|female|     1.0|     3|        0.0|       S|          0.0|\n",
      "|female|     1.0|     2|        2.0|       C|          1.0|\n",
      "|female|     1.0|     3|        0.0|       S|          0.0|\n",
      "|female|     1.0|     1|        1.0|       S|          0.0|\n",
      "|  male|     0.0|     3|        0.0|       S|          0.0|\n",
      "|  male|     0.0|     3|        0.0|       S|          0.0|\n",
      "|female|     1.0|     3|        0.0|       S|          0.0|\n",
      "|female|     1.0|     2|        2.0|       S|          0.0|\n",
      "|  male|     0.0|     3|        0.0|       Q|          2.0|\n",
      "|  male|     0.0|     2|        2.0|       S|          0.0|\n",
      "|female|     1.0|     3|        0.0|       S|          0.0|\n",
      "|female|     1.0|     3|        0.0|       C|          1.0|\n",
      "+------+--------+------+-----------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# resultado\n",
    "bank_df_indexed.select(\"job\", \"marital\", \"education\",\"jobIndex\", \"maritalIndex\", \"educationIndex\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "# Indices\n",
    "index_columns = [\"jobIndex\", \"maritalIndex\", \"educationIndex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnas a vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=index_columns, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|         [22.0,7.25]|\n",
      "|      [38.0,71.2833]|\n",
      "|        [26.0,7.925]|\n",
      "|         [35.0,53.1]|\n",
      "|         [35.0,8.05]|\n",
      "|[29.6991176470588...|\n",
      "|      [54.0,51.8625]|\n",
      "|        [2.0,21.075]|\n",
      "|      [27.0,11.1333]|\n",
      "|      [14.0,30.0708]|\n",
      "|          [4.0,16.7]|\n",
      "|        [58.0,26.55]|\n",
      "|         [20.0,8.05]|\n",
      "|       [39.0,31.275]|\n",
      "|       [14.0,7.8542]|\n",
      "|         [55.0,16.0]|\n",
      "|        [2.0,29.125]|\n",
      "|[29.6991176470588...|\n",
      "|         [31.0,18.0]|\n",
      "|[29.6991176470588...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframe con columnas seleccionadas\n",
    "df_assembled = assembler.transform(bank_df_indexed).select(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación\n",
    "correlation_matrix = Correlation.corr(df_assembled, \"features\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de correlación entre SexIndex, PclassIndex y EmbarkedIndex:\n",
      "DenseMatrix([[ 1.        ,  0.11708532,  0.11859266],\n",
      "             [ 0.11708532,  1.        , -0.16763573],\n",
      "             [ 0.11859266, -0.16763573,  1.        ]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mostrar la matriz: 1 mucha correlacción, 0 poca\n",
    "print(\"Matriz de correlación entre job, marital, education:\")\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+-----+\n",
      "|   Sex|Pclass|Embarked|count|\n",
      "+------+------+--------+-----+\n",
      "|female|     1|       S|   48|\n",
      "|female|     1|       Q|    1|\n",
      "|female|     1|       C|   43|\n",
      "|female|     3|       C|   23|\n",
      "|female|     2|       C|    7|\n",
      "|female|     2|       Q|    2|\n",
      "|female|     3|       S|   88|\n",
      "|female|     3|       Q|   33|\n",
      "|female|     2|       S|   67|\n",
      "|  male|     2|       Q|    1|\n",
      "|  male|     1|       S|   79|\n",
      "|  male|     1|       C|   42|\n",
      "|  male|     2|       C|   10|\n",
      "|  male|     3|       C|   43|\n",
      "|  male|     1|       Q|    1|\n",
      "|  male|     3|       S|  265|\n",
      "|  male|     3|       Q|   39|\n",
      "|  male|     2|       S|   97|\n",
      "+------+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by de las tres variables\n",
    "grouped_df = bank_df.groupBy(\"job\", \"marital\", \"education\").count().orderBy(\"job\")\n",
    "grouped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------------+-------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|       Ticket|   Fare|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------------+-------+--------+\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|        17463|51.8625|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|       349909| 21.075|       S|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|      PP 9549|   16.7|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|       113783|  26.55|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|       248706|   16.0|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|       382652| 29.125|       Q|\n",
      "|         34|       0|     2|Wheadon, Mr. Edwa...|  male|66.0|    0|    0|   C.A. 24579|   10.5|       S|\n",
      "|         44|       1|     2|Laroche, Miss. Si...|female| 3.0|    1|    2|SC/Paris 2123|41.5792|       C|\n",
      "|         53|       1|     1|Harper, Mrs. Henr...|female|49.0|    1|    0|     PC 17572|76.7292|       C|\n",
      "|         55|       0|     1|Ostby, Mr. Engelh...|  male|65.0|    0|    1|       113509|61.9792|       C|\n",
      "|         59|       1|     2|West, Miss. Const...|female| 5.0|    1|    2|   C.A. 34651|  27.75|       S|\n",
      "|         64|       0|     3|Skoog, Master. Ha...|  male| 4.0|    3|    2|       347088|   27.9|       S|\n",
      "|         79|       1|     2|Caldwell, Master....|  male|0.83|    0|    2|       248738|   29.0|       S|\n",
      "|         95|       0|     3|   Coxon, Mr. Daniel|  male|59.0|    0|    0|       364500|   7.25|       S|\n",
      "|         97|       0|     1|Goldschmidt, Mr. ...|  male|71.0|    0|    0|     PC 17754|34.6542|       C|\n",
      "|        117|       0|     3|Connors, Mr. Patrick|  male|70.5|    0|    0|       370369|   7.75|       Q|\n",
      "|        120|       0|     3|Andersson, Miss. ...|female| 2.0|    4|    2|       347082| 31.275|       S|\n",
      "|        125|       0|     1|White, Mr. Perciv...|  male|54.0|    0|    1|        35281|77.2875|       S|\n",
      "|        151|       0|     2|Bateman, Rev. Rob...|  male|51.0|    0|    0|  S.O.P. 1166| 12.525|       S|\n",
      "|        153|       0|     3|    Meo, Mr. Alfonzo|  male|55.5|    0|    0|   A.5. 11206|   8.05|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Outliers edad\n",
    "# Rango intercuartílico (IQR)\n",
    "quantiles = bank_df.approxQuantile(\"age\", [0.25, 0.75], 0.05)\n",
    "Q1 = quantiles[0]\n",
    "Q3 = quantiles[1]\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Límites\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identificar outliers\n",
    "outliers = bank_df.filter((col(\"age\") < lower_bound) | (col(\"age\") > upper_bound))\n",
    "\n",
    "# Mostrarlos\n",
    "outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+--------+--------------------+--------------------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|              Age|SibSp|Parch|          Ticket|   Fare|Embarked|            features|     features_scaled|\n",
      "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+--------+--------------------+--------------------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|             22.0|    1|    0|       A/5 21171|   7.25|       S|         [22.0,7.25]|[0.27117366172405...|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|             38.0|    1|    0|        PC 17599|71.2833|       C|      [38.0,71.2833]|[0.47222920331741...|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|             26.0|    0|    0|STON/O2. 3101282|  7.925|       S|        [26.0,7.925]|[0.32143754712239...|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|             35.0|    1|    0|          113803|   53.1|       S|         [35.0,53.1]|[0.43453128926866...|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|             35.0|    0|    0|          373450|   8.05|       S|         [35.0,8.05]|[0.43453128926866...|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|29.69911764705882|    0|    0|          330877| 8.4583|       Q|[29.6991176470588...|[0.36792055349407...|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|             54.0|    0|    0|           17463|51.8625|       S|      [54.0,51.8625]|[0.67328474491078...|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|              2.0|    3|    1|          349909| 21.075|       S|        [2.0,21.075]|[0.01985423473234...|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|             27.0|    0|    2|          347742|11.1333|       S|      [27.0,11.1333]|[0.33400351847197...|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|             14.0|    1|    0|          237736|30.0708|       C|      [14.0,30.0708]|[0.17064589092736...|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|              4.0|    1|    1|         PP 9549|   16.7|       S|          [4.0,16.7]|[0.04498617743151...|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|             58.0|    0|    0|          113783|  26.55|       S|        [58.0,26.55]|[0.72354863030912...|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|             20.0|    0|    0|       A/5. 2151|   8.05|       S|         [20.0,8.05]|[0.24604171902488...|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|             39.0|    1|    5|          347082| 31.275|       S|       [39.0,31.275]|[0.48479517466700...|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|             14.0|    0|    0|          350406| 7.8542|       S|       [14.0,7.8542]|[0.17064589092736...|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|             55.0|    0|    0|          248706|   16.0|       S|         [55.0,16.0]|[0.68585071626036...|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|              2.0|    4|    1|          382652| 29.125|       Q|        [2.0,29.125]|[0.01985423473234...|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|29.69911764705882|    0|    0|          244373|   13.0|       S|[29.6991176470588...|[0.36792055349407...|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|             31.0|    1|    0|          345763|   18.0|       S|         [31.0,18.0]|[0.38426740387031...|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|29.69911764705882|    0|    0|            2649|  7.225|       C|[29.6991176470588...|[0.36792055349407...|\n",
      "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalizar\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "# Combinar las columnas en un vector\n",
    "assembler = VectorAssembler(inputCols=[\"age\", \"balance\"], outputCol=\"features\")\n",
    "df_assembled = assembler.transform(bank_df)\n",
    "\n",
    "# MinMaxScaler\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "\n",
    "# Ajustar y normalizar\n",
    "scaler_model = scaler.fit(df_assembled)\n",
    "df_normalizado = scaler_model.transform(df_assembled)\n",
    "\n",
    "# Mostrar \n",
    "df_normalizado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+-------------------------------------------------------+------+-----------------+-----+-----+----------------+-------+--------+--------+-----------+-------------+--------------------------+-----------------------------------------+----------------------------------------------------+\n",
      "|PassengerId|Survived|Pclass|Name                                                   |Sex   |Age              |SibSp|Parch|Ticket          |Fare   |Embarked|SexIndex|PclassIndex|EmbarkedIndex|features                  |features_scaled                          |features_total                                      |\n",
      "+-----------+--------+------+-------------------------------------------------------+------+-----------------+-----+-----+----------------+-------+--------+--------+-----------+-------------+--------------------------+-----------------------------------------+----------------------------------------------------+\n",
      "|1          |0       |3     |Braund, Mr. Owen Harris                                |male  |22.0             |1    |0    |A/5 21171       |7.25   |S       |0.0     |0.0        |0.0          |[22.0,7.25]               |[1.696435732564405,0.14588257699617724]  |(5,[0,1],[1.696435732564405,0.14588257699617724])   |\n",
      "|2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)    |female|38.0             |1    |0    |PC 17599        |71.2833|C       |1.0     |1.0        |1.0          |[38.0,71.2833]            |[2.9302071744294267,1.4343436552816002]  |[2.9302071744294267,1.4343436552816002,1.0,1.0,1.0] |\n",
      "|3          |1       |3     |Heikkinen, Miss. Laina                                 |female|26.0             |0    |0    |STON/O2. 3101282|7.925  |S       |1.0     |0.0        |0.0          |[26.0,7.925]              |[2.0048785930306607,0.15946474795789028] |[2.0048785930306607,0.15946474795789028,1.0,0.0,0.0]|\n",
      "|4          |1       |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)           |female|35.0             |1    |0    |113803          |53.1   |S       |1.0     |1.0        |0.0          |[35.0,53.1]               |[2.698875029079735,1.0684641156547603]   |[2.698875029079735,1.0684641156547603,1.0,0.0,1.0]  |\n",
      "|5          |0       |3     |Allen, Mr. William Henry                               |male  |35.0             |0    |0    |373450          |8.05   |S       |0.0     |0.0        |0.0          |[35.0,8.05]               |[2.698875029079735,0.16197996480265198]  |(5,[0,1],[2.698875029079735,0.16197996480265198])   |\n",
      "|6          |0       |3     |Moran, Mr. James                                       |male  |29.69911764705882|0    |0    |330877          |8.4583 |Q       |0.0     |0.0        |2.0          |[29.69911764705882,8.4583]|[2.290120200095667,0.1701956691043815]   |[2.290120200095667,0.1701956691043815,0.0,2.0,0.0]  |\n",
      "|7          |0       |1     |McCarthy, Mr. Timothy J                                |male  |54.0             |0    |0    |17463           |51.8625|S       |0.0     |1.0        |0.0          |[54.0,51.8625]            |[4.1639786162944485,1.0435634688916196]  |[4.1639786162944485,1.0435634688916196,0.0,0.0,1.0] |\n",
      "|8          |0       |3     |Palsson, Master. Gosta Leonard                         |male  |2.0              |3    |1    |349909          |21.075 |S       |0.0     |0.0        |0.0          |[2.0,21.075]              |[0.15422143023312773,0.42406556002681867]|(5,[0,1],[0.15422143023312773,0.42406556002681867]) |\n",
      "|9          |1       |3     |Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)      |female|27.0             |0    |2    |347742          |11.1333|S       |1.0     |0.0        |0.0          |[27.0,11.1333]            |[2.0819893081472243,0.2240213095822814]  |[2.0819893081472243,0.2240213095822814,1.0,0.0,0.0] |\n",
      "|10         |1       |2     |Nasser, Mrs. Nicholas (Adele Achem)                    |female|14.0             |1    |0    |237736          |30.0708|C       |1.0     |2.0        |1.0          |[14.0,30.0708]            |[1.0795500116318941,0.6050766615636753]  |[1.0795500116318941,0.6050766615636753,1.0,1.0,2.0] |\n",
      "|11         |1       |3     |Sandstrom, Miss. Marguerite Rut                        |female|4.0              |1    |1    |PP 9549         |16.7   |S       |1.0     |0.0        |0.0          |[4.0,16.7]                |[0.30844286046625546,0.33603297046016]   |[0.30844286046625546,0.33603297046016,1.0,0.0,0.0]  |\n",
      "|12         |1       |1     |Bonnell, Miss. Elizabeth                               |female|58.0             |0    |0    |113783          |26.55  |S       |1.0     |1.0        |0.0          |[58.0,26.55]              |[4.4724214767607045,0.5342320578273801]  |[4.4724214767607045,0.5342320578273801,1.0,0.0,1.0] |\n",
      "|13         |0       |3     |Saundercock, Mr. William Henry                         |male  |20.0             |0    |0    |A/5. 2151       |8.05   |S       |0.0     |0.0        |0.0          |[20.0,8.05]               |[1.5422143023312773,0.16197996480265198] |(5,[0,1],[1.5422143023312773,0.16197996480265198])  |\n",
      "|14         |0       |3     |Andersson, Mr. Anders Johan                            |male  |39.0             |1    |5    |347082          |31.275 |S       |0.0     |0.0        |0.0          |[39.0,31.275]             |[3.0073178895459907,0.6293072545593714]  |(5,[0,1],[3.0073178895459907,0.6293072545593714])   |\n",
      "|15         |0       |3     |Vestrom, Miss. Hulda Amanda Adolfina                   |female|14.0             |0    |0    |350406          |7.8542 |S       |1.0     |0.0        |0.0          |[14.0,7.8542]             |[1.0795500116318941,0.1580401291370173]  |[1.0795500116318941,0.1580401291370173,1.0,0.0,0.0] |\n",
      "|16         |1       |2     |Hewlett, Mrs. (Mary D Kingcome)                        |female|55.0             |0    |0    |248706          |16.0   |S       |1.0     |2.0        |0.0          |[55.0,16.0]               |[4.241089331411013,0.3219477561294946]   |[4.241089331411013,0.3219477561294946,1.0,0.0,2.0]  |\n",
      "|17         |0       |3     |Rice, Master. Eugene                                   |male  |2.0              |4    |1    |382652          |29.125 |Q       |0.0     |0.0        |2.0          |[2.0,29.125]              |[0.15422143023312773,0.5860455248294707] |[0.15422143023312773,0.5860455248294707,0.0,2.0,0.0]|\n",
      "|18         |1       |2     |Williams, Mr. Charles Eugene                           |male  |29.69911764705882|0    |0    |244373          |13.0   |S       |0.0     |2.0        |0.0          |[29.69911764705882,13.0]  |[2.290120200095667,0.2615825518552144]   |[2.290120200095667,0.2615825518552144,0.0,0.0,2.0]  |\n",
      "|19         |0       |3     |Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)|female|31.0             |1    |0    |345763          |18.0   |S       |1.0     |0.0        |0.0          |[31.0,18.0]               |[2.3904321686134797,0.36219122564568146] |[2.3904321686134797,0.36219122564568146,1.0,0.0,0.0]|\n",
      "|20         |1       |3     |Masselmani, Mrs. Fatima                                |female|29.69911764705882|0    |0    |2649            |7.225  |C       |1.0     |0.0        |1.0          |[29.69911764705882,7.225] |[2.290120200095667,0.14537953362722492]  |[2.290120200095667,0.14537953362722492,1.0,1.0,0.0] |\n",
      "+-----------+--------+------+-------------------------------------------------------+------+-----------------+-----+-----+----------------+-------+--------+--------+-----------+-------------+--------------------------+-----------------------------------------+----------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estandarizar\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "# Combinar columnas\n",
    "assembler = VectorAssembler(inputCols=[\"age\", \"balance\"], outputCol=\"features\")\n",
    "df_assembled = assembler.transform(bank_df_indexed)\n",
    "\n",
    "# StandardScaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "\n",
    "# Ajustar \n",
    "scaler_model = scaler.fit(df_assembled)\n",
    "df_estandarizado = scaler_model.transform(df_assembled)\n",
    "\n",
    "# Combinar categóricas convertidas y numéricas en un vector\n",
    "assembler_total = VectorAssembler(inputCols=[\"features_scaled\", \"jobIndex\",\"maritalIndex\",\"educationIndex\"], outputCol=\"features_total\")\n",
    "df_final = assembler_total.transform(df_estandarizado)\n",
    "\n",
    "df_final.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
